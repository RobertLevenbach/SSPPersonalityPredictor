{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pickle\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read video URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdata():\n",
    "    \n",
    "    datapath = os.getcwd() +\"\\\\videos\"\n",
    "    onlyfiles = [f for f in listdir(datapath) if isfile(join(datapath, f))]\n",
    "\n",
    "    return onlyfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read personality label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdatapersonality():\n",
    "    \n",
    "    labelpath = os.getcwd() + \"\\\\annotation_training.pkl\"\n",
    "    with open(labelpath, 'rb') as f:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        labeldata = u.load()\n",
    "    \n",
    "    return labeldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YouTube function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_build():\n",
    "\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,developerKey=DEVELOPER_KEY)\n",
    "\n",
    "    return youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract video's comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(service, **kwargs):\n",
    "    \n",
    "    comments = []\n",
    "    usernames = []\n",
    "    dates = []\n",
    "    likes = []\n",
    "    \n",
    "    try:\n",
    "        results = service.commentThreads().list(**kwargs).execute()\n",
    "    except Exception:\n",
    "        return False\n",
    " \n",
    "    while results:\n",
    "        if len(comments) == 300:\n",
    "            break\n",
    "        \n",
    "        for item in results['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    "            username = item['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "            usernames.append(username)\n",
    "            date = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "            dates.append(date)\n",
    "            like = item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "            likes.append(like)\n",
    " \n",
    "        if 'nextPageToken' in results:\n",
    "            kwargs['pageToken'] = results['nextPageToken']\n",
    "            results = service.commentThreads().list(**kwargs).execute()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if len(comments) == 0:\n",
    "        return False\n",
    "            \n",
    "    d = {'Comment':comments,'Username':usernames,'Date':dates,'Like':likes}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get personalities value for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personalities(vid, lab):\n",
    "\n",
    "    d = {'Agreeableness':lab['agreeableness'][vid], 'Conscientiousness':lab['conscientiousness'][vid],\n",
    "         'Extraversion':lab['extraversion'][vid], 'Neuroticism':lab['neuroticism'][vid],\n",
    "         'Openness':lab['openness'][vid]}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine comment and personality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractdata(listvideo, listlabel):\n",
    "    \n",
    "    cmlist = []\n",
    "    vidchecker = '';\n",
    "    \n",
    "    for video in listvideo:\n",
    "        if video[:-8] == vidchecker:\n",
    "            continue\n",
    "        vidchecker = video[:-8]\n",
    "        comment_data = get_video_comments(youtube_build(), part='snippet', videoId=video[:-8], textFormat='plainText')\n",
    "        person_data = get_personalities(video, listlabel)\n",
    "        if comment_data == False:\n",
    "            continue\n",
    "        d = {'Video':video[:-8],'Personality':person_data, 'Data':comment_data}\n",
    "        cmlist.append(d)\n",
    "    \n",
    "    return cmlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write and save combined data in JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(cmlist):\n",
    "    \n",
    "    with open('ssp2.json', 'a') as fp: #your file may be saved in here (print this) -> os.getcwd()\n",
    "        json.dump(cmlist, fp)\n",
    "    fp.close()\n",
    "    \n",
    "    f = open('ssp2.json','r')\n",
    "    old_data = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    new_data = old_data.replace(\"][\", \",\")\n",
    "    \n",
    "    f = open('ssp2_new.json','w')\n",
    "    f.write(new_data)\n",
    "    f.close()\n",
    "    \n",
    "    os.remove('ssp2.json') \n",
    "    os.rename('ssp2_new.json', 'ssp2.json')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile():\n",
    "    with open('ssp2.json', 'r') as fp: \n",
    "        complistnew = json.load(fp)\n",
    "\n",
    "    cmlistnew = sorted(complistnew, key=itemgetter('Video'))\n",
    "    \n",
    "    return cmlistnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVELOPER_KEY = \"AIzaSyDp4gj0bM-e0qAH0EA6VdGDUQSt2Pnk-B4\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "list_of_videonames = readdata()\n",
    "list_of_labels = readdatapersonality()\n",
    "\n",
    "complist = extractdata(list_of_videonames, list_of_labels)\n",
    "\n",
    "writefile(complist)\n",
    "\n",
    "complistnew = readfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_data_train = []\n",
    "label_data_train = [[] for i in range(5)]\n",
    "comment_data_test = []\n",
    "label_data_test = [[] for i in range(5)]\n",
    "category = ['Agreeableness', 'Conscientiousness', 'Extraversion', 'Neuroticism', 'Openness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viddata in complistnew:\n",
    "    tempcom = ''\n",
    "    templist = []\n",
    "    for comdata in viddata['Data']['Comment']:\n",
    "        if tempcom == '':\n",
    "            tempcom = comdata\n",
    "        else:\n",
    "            tempcom = tempcom + \" \" + comdata\n",
    "    comment_data_train.append(tempcom)\n",
    "    label_data_train[0].append(determineclass(viddata['Personality']['Agreeableness'], 0))\n",
    "    label_data_train[1].append(determineclass(viddata['Personality']['Conscientiousness'], 1))\n",
    "    label_data_train[2].append(determineclass(viddata['Personality']['Extraversion'], 2))\n",
    "    label_data_train[3].append(determineclass(viddata['Personality']['Neuroticism'], 3))\n",
    "    label_data_train[4].append(determineclass(viddata['Personality']['Openness'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viddata in complistnew2:\n",
    "    tempcom = ''\n",
    "    for comdata in viddata['Data']['Comment']:\n",
    "        if tempcom == '':\n",
    "            tempcom = comdata\n",
    "        else:\n",
    "            tempcom = tempcom + \" \" + comdata\n",
    "    comment_data_test.append(tempcom)\n",
    "    label_data_test[0].append(determineclass(viddata['Personality']['Agreeableness'], 0))\n",
    "    label_data_test[1].append(determineclass(viddata['Personality']['Conscientiousness'], 1))\n",
    "    label_data_test[2].append(determineclass(viddata['Personality']['Extraversion'], 2))\n",
    "    label_data_test[3].append(determineclass(viddata['Personality']['Neuroticism'], 3))\n",
    "    label_data_test[4].append(determineclass(viddata['Personality']['Openness'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipeline_cnt = Pipeline([\n",
    "                ('count', CountVectorizer(lowercase=True, ngram_range=(1,2), stop_words='english')),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Performance Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for cat in category:\n",
    "    print('... Processing {}'.format(cat))\n",
    "    NB_pipeline_cnt.fit(comment_data_train, label_data_train[count])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline_cnt.predict(comment_data_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(label_data_test[count], prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipeline_tid = Pipeline([\n",
    "                ('count', TfIdfVectorizer(lowercase=True, ngram_range=(1,2), stop_words='english')),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Performance TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for cat in category:\n",
    "    print('... Processing {}'.format(cat))\n",
    "    NB_pipeline_tid.fit(comment_data_train, label_data_train[count])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline_tid.predict(comment_data_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(label_data_test[count], prediction)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
